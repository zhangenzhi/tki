experiment:
  context:
    name: online-CA3 #cifar10-MA13 #for each exp
    # devices: 1
    # multi-p: 1
    # dist:
    #   devices: 4
    log_path: ./log

  main_loop:
    warmup: 
      student_nums: 3
      supervisor_iters: 1
    nums: 30
    student_nums: 1

  student:
    name: oclr
    dataloader:
      name: cifar10 # cifar100, mnist
      batch_size: 128
      epochs: 120
      da: False # data augumentation
    model:
      # name: resnet56
      # classes: 10 
      name: dnn
      units: [128,64,32,10] 
      activations: [relu,relu,relu,softmax] 
    loss:
      name: CategoricalCrossentropy
    metrics: 
      name: CategoricalAccuracy
    optimizer:
      name: sgd 
      learning_rate: 0.1 
    train_loop:
        train:
          lr_decay: False # decay
          discount_factor: 0.9
          action:
            style: fix_n
            act_space: [-0.01,0.0,0.01]
          policy: 
            style: epsilon_greedy
            epsilon: 0.90
        valid:
          q_style: multi_action #multi_action
          save_knowledge: ["state", "reward", "act_idx"]
          discount_factor: 0.5
          weights_style: flat_imagelization # imagelization
          valid_gap: 30
          online: False
        test:
          epoch: -1
        visual: False

  supervisor:
    name: naive
    dataloader:
      name: dnn_RL
      exp: decay
      replay_window: 15
      batch_size: 32
      epochs: 50
    model:
      name: dnn # default dnn
      units: [128,64,32,3] # default 128,64,32,3
      activations: [relu,relu,relu,relu] # default relu
      normalization: False
      downsampling: True
    optimizer:
      name: sgd
      learning_rate: 0.01
    loss:
      name: MeanAbsoluteError #MeanAbsoluteError 
    metrics: 
      name: MeanSquaredError
    train_loop:
        train:
          lr_decay: False # decay
          weights_style: flat_imagelization # stack_imagelization
        valid:
          valid_gap: 100
          epoch: -1
        test:
          epoch: -1